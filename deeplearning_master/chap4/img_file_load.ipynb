{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35a3983-bb1e-471c-afe3-3f13a4689d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e647b64c-374e-4a68-ba0c-9b7bee24b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (2.33.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from imageio) (1.26.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /root/miniconda3/envs/pytorch/lib/python3.10/site-packages (from imageio) (10.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ef4469-d0ce-40dd-b17c-8edf98db89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eab409e-33c2-4280-aad6-1ba4e41ba5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34f7a8b-ebf6-4852-a06e-4b29e6e03e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype = torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94b8c54-18b5-4f09-b094-60b38f0b0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = '../data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b5872c-2e53-4731-856e-d4df2c721a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0 # 정규화를 위해 8비트 정수의 최댓값으로 나눈다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440102f6-4c1a-4593-8676-9ca81bae52a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "n_channels = batch.shape[1]\n",
    "print(batch.shape[1])\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c]) # 배치의 처음부터 끝까지 0번째 채널들을 다 합하고 그 수만큼 나눔\n",
    "    std = torch.std(batch[:, c]) # 배치의 처음부터 끝가지 0 번째 채널들의 각 요소들을 제곱해서 더한 그 수만큼 나눔\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d740c4-8904-4419-a5f3-5653f916f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1439,  0.0730, -0.4234,  ...,  0.0375,  0.0198,  0.1794],\n",
      "          [ 0.4631, -0.2461,  0.3035,  ..., -0.4944, -0.2107, -0.1752],\n",
      "          [-0.3703,  0.1439, -0.7249,  ..., -0.2993, -0.0866,  0.2858],\n",
      "          ...,\n",
      "          [-0.5653, -0.3171, -0.3348,  ..., -0.3703, -0.5298, -0.6362],\n",
      "          [-0.3348, -0.3171, -0.4412,  ..., -0.5830, -0.4766, -0.6007],\n",
      "          [-0.3348, -0.4412, -0.5298,  ..., -0.6185, -0.4766, -0.4944]],\n",
      "\n",
      "         [[ 0.4632,  0.3874, -0.1058,  ...,  0.3874,  0.3874,  0.6150],\n",
      "          [ 0.8615,  0.0839,  0.6529,  ..., -0.1816,  0.1408,  0.1787],\n",
      "          [-0.0299,  0.4822, -0.4661,  ...,  0.0649,  0.2736,  0.7098],\n",
      "          ...,\n",
      "          [-0.2954, -0.0868, -0.0678,  ...,  0.0460, -0.1247, -0.2196],\n",
      "          [-0.0678, -0.0678, -0.1627,  ..., -0.1627, -0.0489, -0.1816],\n",
      "          [-0.0678, -0.2006, -0.2385,  ..., -0.2196, -0.0868, -0.0678]],\n",
      "\n",
      "         [[ 0.7792,  0.6573,  0.1495,  ...,  0.8198,  0.8401,  1.1041],\n",
      "          [ 1.3072,  0.3933,  0.9417,  ...,  0.2308,  0.5761,  0.6167],\n",
      "          [ 0.2714,  0.8401, -0.2161,  ...,  0.4339,  0.6979,  1.1245],\n",
      "          ...,\n",
      "          [ 0.0480,  0.3526,  0.2917,  ...,  0.6979,  0.4948,  0.3526],\n",
      "          [ 0.3526,  0.3526,  0.1495,  ...,  0.3933,  0.5354,  0.3933],\n",
      "          [ 0.3323,  0.1495,  0.0886,  ...,  0.3526,  0.4948,  0.5151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9595,  0.7999,  0.7467,  ..., -2.3915, -2.3915, -2.4092],\n",
      "          [ 0.9063,  0.7822,  0.7290,  ..., -2.3738, -2.3738, -2.3738],\n",
      "          [ 0.8886,  0.7999,  0.7113,  ..., -2.4092, -2.4092, -2.4092],\n",
      "          ...,\n",
      "          [-0.9731, -1.1681, -1.2745,  ..., -1.9837, -1.9837, -1.9837],\n",
      "          [-1.2922, -1.4163, -0.8312,  ..., -1.9837, -1.9837, -1.9660],\n",
      "          [-1.1149, -0.7958, -1.0263,  ..., -1.9837, -1.9660, -1.9482]],\n",
      "\n",
      "         [[ 0.6908,  0.4632,  0.3494,  ..., -2.0024, -2.0024, -2.0214],\n",
      "          [ 0.6908,  0.4822,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n",
      "          [ 0.7098,  0.5391,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n",
      "          ...,\n",
      "          [-1.0920, -1.3196, -1.4334,  ..., -1.6800, -1.6800, -1.6800],\n",
      "          [-1.5472, -1.6800, -1.0541,  ..., -1.6800, -1.6800, -1.6610],\n",
      "          [-1.4144, -1.0730, -1.3196,  ..., -1.6800, -1.6610, -1.6420]],\n",
      "\n",
      "         [[-0.4598, -0.7644, -0.9472,  ..., -1.7190, -1.7190, -1.7394],\n",
      "          [-0.4801, -0.7441, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n",
      "          [-0.4801, -0.7035, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n",
      "          ...,\n",
      "          [-1.2113, -1.4550, -1.5972,  ..., -1.4956, -1.4956, -1.4956],\n",
      "          [-1.6175, -1.8003, -1.1300,  ..., -1.4956, -1.4956, -1.4753],\n",
      "          [-1.4550, -1.0894, -1.3941,  ..., -1.4956, -1.4753, -1.4550]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "          ...,\n",
      "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6936,  0.7467,  0.7999],\n",
      "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822],\n",
      "          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822]],\n",
      "\n",
      "         [[ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
      "          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
      "          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n",
      "          ...,\n",
      "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2765, -0.2196, -0.1627],\n",
      "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816],\n",
      "          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816]],\n",
      "\n",
      "         [[ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
      "          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
      "          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n",
      "          ...,\n",
      "          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4598, -0.3785],\n",
      "          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4395, -0.3988],\n",
      "          [-0.2364, -0.2567, -0.2770,  ..., -0.5207, -0.4395, -0.3785]]]])\n",
      "\n",
      "torch.Size([3, 3, 256, 256])\n",
      "\n",
      "tensor([[[ 0.1439,  0.0730, -0.4234,  ...,  0.0375,  0.0198,  0.1794],\n",
      "         [ 0.4631, -0.2461,  0.3035,  ..., -0.4944, -0.2107, -0.1752],\n",
      "         [-0.3703,  0.1439, -0.7249,  ..., -0.2993, -0.0866,  0.2858],\n",
      "         ...,\n",
      "         [-0.5653, -0.3171, -0.3348,  ..., -0.3703, -0.5298, -0.6362],\n",
      "         [-0.3348, -0.3171, -0.4412,  ..., -0.5830, -0.4766, -0.6007],\n",
      "         [-0.3348, -0.4412, -0.5298,  ..., -0.6185, -0.4766, -0.4944]],\n",
      "\n",
      "        [[ 0.9595,  0.7999,  0.7467,  ..., -2.3915, -2.3915, -2.4092],\n",
      "         [ 0.9063,  0.7822,  0.7290,  ..., -2.3738, -2.3738, -2.3738],\n",
      "         [ 0.8886,  0.7999,  0.7113,  ..., -2.4092, -2.4092, -2.4092],\n",
      "         ...,\n",
      "         [-0.9731, -1.1681, -1.2745,  ..., -1.9837, -1.9837, -1.9837],\n",
      "         [-1.2922, -1.4163, -0.8312,  ..., -1.9837, -1.9837, -1.9660],\n",
      "         [-1.1149, -0.7958, -1.0263,  ..., -1.9837, -1.9660, -1.9482]],\n",
      "\n",
      "        [[ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "         [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "         [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n",
      "         ...,\n",
      "         [ 1.1723,  1.1545,  1.1368,  ...,  0.6936,  0.7467,  0.7999],\n",
      "         [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822],\n",
      "         [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822]]])\n"
     ]
    }
   ],
   "source": [
    "print(batch)\n",
    "print()\n",
    "print(batch.shape)\n",
    "print()\n",
    "print(batch[:, 0]) # 배치의 처음부터 끝까지 0번 째 채널만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc33add1-4e8e-41b9-9327-d36246bc2ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%11/99 files (11.1%21/99 files (21.2%31/99 files (31.3%41/99 files (41.4%51/99 files (51.5%60/99 files (60.6%71/99 files (71.7%80/99 files (80.8%90/99 files (90.9%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 20/99  (20.241/99  (41.461/99  (61.682/99  (82.899/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"../data/p1ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM') # 파일에 있는 데이터를 연속된 형태로 조합해서 3차원 넘파이 배열을 만든다\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1fdf19-e6e7-46ef-9371-b3ce23c977e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db40dc2b-4084-48c5-bae9-7f8ada22b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "wine_path = \"../data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",\n",
    "                         skiprows=1) #skiprows = 1은 1 번째 줄을 건너뛰라는 명령,1 번째줄이 헤더일때 유용\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c19e751-d5d7-45dc-9e64-29cadc84a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6db5ee0-78b4-49d7-ae22-eeec9afd7c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e34a14eb-35b2-4de8-9135-79f72153fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1] # 모든 행, 마지막 열(레이블)을 제외한 모든 열\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75dd72a2-ff94-4a7c-8ef3-1cbe9fb16776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb01030-88ad-47b2-81a2-be88507b1d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127ee7fb-61e0-440f-975f-1334834fb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69e9253-2eeb-48bd-9aba-5a2953859fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9ff9f5-eb32-4296-b757-2c6b70f2dd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f557f1b-5f03-4507-b15a-d88a7bfc965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0) # dim=0에서 분산을 구함\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28ea17b5-231e-481a-802a-18328710d7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd1aa7cc-9c2a-4e73-8eff-59576f716e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d221dc7-fcf4-41bc-baff-8512ddb3d9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcefa948-3074-4302-abba-d63d70ec1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0fixed acidity         7.60  6.89  6.73\n",
      " 1volatile acidity      0.33  0.28  0.27\n",
      " 2citric acid           0.34  0.34  0.33\n",
      " 3residual sugar        6.39  6.71  5.26\n",
      " 4chlorides             0.05  0.05  0.04\n",
      " 5free sulfur dioxide  53.33 35.42 34.55\n",
      " 6total sulfur dioxide170.60141.83125.25\n",
      " 7density               0.99  0.99  0.99\n",
      " 8pH                    3.19  3.18  3.22\n",
      " 9sulphates             0.47  0.49  0.50\n",
      "10alcohol              10.34 10.26 11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data =data[target <=3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data =data[target >=7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2}{:20}{:6.2f}{:6.2f}{:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d228c2d-9e03-420c-bd1e-fbe61fddc293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold =141.83\n",
    "total_sulfur_data = data[:,6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c3f5c5-d354-4938-8831-ccc73b701b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a6e8c6d-63c6-4466-be82-6a3df1374faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35da470b-2dd7-4ff5-8019-229e52b2995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy = np.loadtxt(\n",
    "    \"../data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])})\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60986a58-ea89-4a02-be10-c95dbe06a13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02ddf1cd-24a1-414c-a299-69ecbb677be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0df4f61b-3bc6-40a6-ac92-5308733bb66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(2,1)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a77ec74-e0ec-4c35-a6ea-18b956cb1ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long() \n",
    "# long() 은 정수값을 표현하고 처리하기 위해 사용했으나, 현재 파이썬 3.x버전 부터는 기본적으로 정수를 처리하기 때문에 사용할 일이 없다\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "first_day[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e10ea009-833a-420f-8511-51ec708a3044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1,   1,   1,   0,   1,   0,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            3,  13,  16],\n",
       "         [  2,   1,   1,   0,   1,   1,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            8,  32,  40],\n",
       "         [  3,   1,   1,   0,   1,   2,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            5,  27,  32],\n",
       "         [  4,   1,   1,   0,   1,   3,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            3,  10,  13],\n",
       "         [  5,   1,   1,   0,   1,   4,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            0,   1,   1],\n",
       "         [  6,   1,   1,   0,   1,   5,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "            0,   1,   1],\n",
       "         [  7,   1,   1,   0,   1,   6,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            2,   0,   2],\n",
       "         [  8,   1,   1,   0,   1,   7,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            1,   2,   3],\n",
       "         [  9,   1,   1,   0,   1,   8,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            1,   7,   8],\n",
       "         [ 10,   1,   1,   0,   1,   9,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "            8,   6,  14],\n",
       "         [ 11,   1,   1,   0,   1,  10,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           12,  24,  36],\n",
       "         [ 12,   1,   1,   0,   1,  11,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           26,  30,  56],\n",
       "         [ 13,   1,   1,   0,   1,  12,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           29,  55,  84],\n",
       "         [ 14,   1,   1,   0,   1,  13,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           47,  47,  94],\n",
       "         [ 15,   1,   1,   0,   1,  14,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           35,  71, 106],\n",
       "         [ 16,   1,   1,   0,   1,  15,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           40,  70, 110],\n",
       "         [ 17,   1,   1,   0,   1,  16,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           41,  52,  93],\n",
       "         [ 18,   1,   1,   0,   1,  17,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           15,  52,  67],\n",
       "         [ 19,   1,   1,   0,   1,  18,   0,   6,   0,   3,   0,   0,   0,   0,\n",
       "            9,  26,  35],\n",
       "         [ 20,   1,   1,   0,   1,  19,   0,   6,   0,   3,   0,   0,   0,   0,\n",
       "            6,  31,  37],\n",
       "         [ 21,   1,   1,   0,   1,  20,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           11,  25,  36],\n",
       "         [ 22,   1,   1,   0,   1,  21,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "            3,  31,  34],\n",
       "         [ 23,   1,   1,   0,   1,  22,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           11,  17,  28],\n",
       "         [ 24,   1,   1,   0,   1,  23,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           15,  24,  39]]),\n",
       " torch.Size([24, 17]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day, first_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1139688b-ccf5-46c6-a792-43473acb3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(\n",
    "    dim=1, \n",
    "    index=first_day[:,9].unsqueeze(1).long() - 1, \n",
    "    value=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0af96283-b1f3-4c65-ac9a-16a9c8a05c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c72f789-43c5-4759-a66f-6fa2bb77b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4,\n",
    "                                   daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4600b598-d267-4109-a8ba-6a1fef370f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(\n",
    "    1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7b28989-2c84-4768-87bc-1fbfb0c39cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22ff9a76-8e2e-431a-b512-6f108db4427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5899f00b-ae7f-49ee-a9b8-3bfa60e70b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - temp_min)\n",
    "                         / (temp_max - temp_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81ef480f-9110-4ddb-ac5f-07bdced87164",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp))\n",
    "                         / torch.std(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f00573-568c-4ef0-8397-c0c22eae144e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5671d6-c128-46d4-9be7-5109e41c7cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35a0a5-4022-4bd7-bfa8-7a9b61a9a725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b854c-6d3e-4ffb-b358-93561f6b658d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7229129-4033-435f-90a7-ea35204b55d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c441ce-9743-493c-b844-56c4494366b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb91f52-df27-4b04-9c30-6af37c785c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
